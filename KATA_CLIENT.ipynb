{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e4tZlQNlAOVV",
        "outputId": "3f71f11f-0645-4edd-f2b9-d01386781219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-04-25 07:40:08--  https://gist.githubusercontent.com/korakot/8409b3feec20f159d8a50b0a811d3bca/raw/63788418ef51add8a0ddd4664a97910cf674415d/draw.py\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1147 (1.1K) [text/plain]\n",
            "Saving to: ‘draw.py.2’\n",
            "\n",
            "\rdraw.py.2             0%[                    ]       0  --.-KB/s               \rdraw.py.2           100%[===================>]   1.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-25 07:40:08 (36.7 MB/s) - ‘draw.py.2’ saved [1147/1147]\n",
            "\n",
            "Requirement already satisfied: flwr in /usr/local/lib/python3.7/dist-packages (0.18.0)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.1 in /usr/local/lib/python3.7/dist-packages (from flwr) (3.17.3)\n",
            "Requirement already satisfied: grpcio<=1.43.0,>=1.27.2 in /usr/local/lib/python3.7/dist-packages (from flwr) (1.43.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from flwr) (1.21.6)\n",
            "Collecting importlib-metadata<2.0.0,>=1.4.0\n",
            "  Using cached importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: google<3.0.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from flwr) (2.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google<3.0.0,>=2.0.3->flwr) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.27.2->flwr) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<2.0.0,>=1.4.0->flwr) (3.8.0)\n",
            "Installing collected packages: importlib-metadata\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.3\n",
            "    Uninstalling importlib-metadata-4.11.3:\n",
            "      Successfully uninstalled importlib-metadata-4.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed importlib-metadata-1.7.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Using cached importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: importlib-metadata\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 1.7.0\n",
            "    Uninstalling importlib-metadata-1.7.0:\n",
            "      Successfully uninstalled importlib-metadata-1.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flwr 0.18.0 requires importlib-metadata<2.0.0,>=1.4.0; python_version < \"3.8\", but you have importlib-metadata 4.11.3 which is incompatible.\u001b[0m\n",
            "Successfully installed importlib-metadata-4.11.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Install the different library needed\n",
        "!wget https://gist.githubusercontent.com/korakot/8409b3feec20f159d8a50b0a811d3bca/raw/63788418ef51add8a0ddd4664a97910cf674415d/draw.py\n",
        "!pip install flwr\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--VzjnPG2bQq"
      },
      "outputs": [],
      "source": [
        "#Import the library\n",
        "import tensorflow as tf\n",
        "import flwr as fl\n",
        "import cv2\n",
        "import numpy as np\n",
        "from draw import draw\n",
        "from os.path import exists\n",
        "from client import MNISTClient_test,model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyvg5lnz3frw",
        "outputId": "36b18358-4b64-4946-a5aa-54f6ccd26fca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘train’: File exists\n"
          ]
        }
      ],
      "source": [
        "#Create the different folder where the training images will be stored\n",
        "import os\n",
        "!mkdir train\n",
        "\n",
        "for i in range(10):\n",
        "  os.system(\" mkdir train/\" + str(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "78C1SlfB2i77",
        "outputId": "b05a1bee-459e-4d0e-852f-04d82a5d1473"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<canvas width=420 height=420></canvas>\n",
              "<button>Finish</button>\n",
              "<script>\n",
              "var canvas = document.querySelector('canvas')\n",
              "var ctx = canvas.getContext('2d')\n",
              "ctx.lineWidth = 15\n",
              "var button = document.querySelector('button')\n",
              "var mouse = {x: 0, y: 0}\n",
              "\n",
              "canvas.addEventListener('mousemove', function(e) {\n",
              "  mouse.x = e.pageX - this.offsetLeft\n",
              "  mouse.y = e.pageY - this.offsetTop\n",
              "})\n",
              "canvas.onmousedown = ()=>{\n",
              "  ctx.beginPath()\n",
              "  ctx.moveTo(mouse.x, mouse.y)\n",
              "  canvas.addEventListener('mousemove', onPaint)\n",
              "}\n",
              "canvas.onmouseup = ()=>{\n",
              "  canvas.removeEventListener('mousemove', onPaint)\n",
              "}\n",
              "var onPaint = ()=>{\n",
              "  ctx.lineTo(mouse.x, mouse.y)\n",
              "  ctx.stroke()\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "  button.onclick = ()=>{\n",
              "    resolve(canvas.toDataURL('image/png'))\n",
              "  }\n",
              "})\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'28*15'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Create some training example\n",
        "number_to_draw = \"0\" #@param {type:\"string\"}\n",
        "test_number = 0\n",
        "file_name = \"train/\" + number_to_draw + \"/test\" + str(test_number) + \".jpg\"\n",
        "\n",
        "while exists(file_name):\n",
        "  test_number +=1\n",
        "  file_name = \"train/\" + str(number_to_draw) + \"/test\" + str(test_number) + \".jpg\"\n",
        "\n",
        "draw(filename = file_name, w=28*15, h=28*15, line_width=15)\n",
        "'''28*15'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6aMcTuykF9m"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVdPyy_92pPs",
        "outputId": "871207cb-d26a-4f09-9656-8b2a75f025e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "(28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "for dirs in os.walk(\"train/\", topdown=False):\n",
        "  root, dirs1, files = dirs\n",
        "  if files != []:\n",
        "    for file in files:\n",
        "      path = dirs[0] + \"/\"\n",
        "      image = cv2.imread( path  + file,cv2.IMREAD_UNCHANGED)\n",
        "      #make mask of where the transparent bits are\n",
        "      trans_mask = image[:,:,3] == 0\n",
        "\n",
        "      #replace areas of transparency with white and not transparent\n",
        "      image[trans_mask] = [255, 255, 255, 255]\n",
        "\n",
        "      #new image without alpha channel...\n",
        "      new_img = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
        "      new_img = cv2.resize(new_img, dsize = (28,28), interpolation = cv2.INTER_CUBIC)\n",
        "      gray = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
        "      gray = gray\n",
        "      for i in range(len(gray)):\n",
        "        for j in range(len(gray[0])):\n",
        "          if gray[i][j] == 255:\n",
        "            gray[i][j] = 0\n",
        "          else :\n",
        "            gray[i][j] = 255\n",
        "\n",
        "      cv2.imwrite(\"image_test1.jpg\",gray)\n",
        "      gray = gray/255\n",
        "      gray = tf.reshape(gray,gray.shape+(1,))\n",
        "      X_train.append(gray)\n",
        "      y_train.append(int(path[len(path)-2]))\n",
        "\n",
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MH4xAksDUQkU"
      },
      "outputs": [],
      "source": [
        "(X_train_google, y_train_google), (X_test_google, y_test_google) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy1WIxdpcqZl"
      },
      "outputs": [],
      "source": [
        "client = MNISTClient_test(\n",
        "    X_train = X_train,\n",
        "    y_train = y_train,\n",
        "    X_test = X_test_google,\n",
        "    y_test = y_test_google,\n",
        "    model = model\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYXFbeUhZrFs",
        "outputId": "10ac442f-2521-46dc-d588-3e20cdf5344a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17, 28, 28, 1)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIKLiW0uop_M",
        "outputId": "89db5e1e-d180-4c39-ddaa-263fcb67fa24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIh_pHf7UgN1",
        "outputId": "0018bb3b-1d8b-4115-c036-f8fc57f8b184"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2022-04-25 08:01:26,664 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
            "DEBUG flower 2022-04-25 08:01:26,668 | connection.py:39 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-04-25 08:01:26,672 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
            "DEBUG flower 2022-04-25 08:01:26,856 | connection.py:39 | ChannelConnectivity.READY\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/3 [=========>....................] - ETA: 0s - loss: 1.4903 - accuracy: 0.5294WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4903 - accuracy: 0.5294\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 305.0093 - accuracy: 0.1961\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.4313 - accuracy: 0.5294WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.4313 - accuracy: 0.5294\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 321.6327 - accuracy: 0.2166\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.3680 - accuracy: 0.6471WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.3680 - accuracy: 0.6471\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 340.0478 - accuracy: 0.2286\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.3006 - accuracy: 0.6471WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.3006 - accuracy: 0.6471\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 361.8161 - accuracy: 0.2373\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.2301 - accuracy: 0.7059WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2301 - accuracy: 0.7059\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 387.3844 - accuracy: 0.2391\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.1574 - accuracy: 0.8235WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.1574 - accuracy: 0.8235\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 416.7017 - accuracy: 0.2395\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0830 - accuracy: 0.8235WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0830 - accuracy: 0.8235\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 449.3033 - accuracy: 0.2332\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0087 - accuracy: 0.8824WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.8824\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 484.2958 - accuracy: 0.2288\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.9352 - accuracy: 0.8235WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9352 - accuracy: 0.8235\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 520.0668 - accuracy: 0.2270\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.8629 - accuracy: 0.8235WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.8629 - accuracy: 0.8235\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 554.9241 - accuracy: 0.2242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2022-04-25 08:02:17,978 | connection.py:121 | gRPC channel closed\n",
            "INFO flower 2022-04-25 08:02:17,981 | app.py:101 | Disconnect and shut down\n"
          ]
        }
      ],
      "source": [
        "# Start Flower client\n",
        "fl.client.start_numpy_client(server_address='90.84.246.40:8080', client=client)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "KATA_CLIENT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}